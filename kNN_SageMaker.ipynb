{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules, specify bucket, construct error handling structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import matploblib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "import os\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "bucket = 'es-code-backup422'\n",
    "prefix = 'SageMaker'\n",
    "execution_role = sagemaker.get_execution_role()\n",
    "\n",
    "try:\n",
    "    boto3.Session().client('s3').head_bucket(Bucket=bucket)\n",
    "except botocore.exceptions.ParamValidationError as e:\n",
    "    print('No bucket specified/wrong name error.')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == '403':\n",
    "print(\"Permission error for this bucket, {}.\".format(bucket))\n",
    "    elif e.response['Error']['Code'] == '404':\n",
    "print(\"Bucket was not found.\".format(bucket))\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    print('All data and output will be stored in: s3://{}/{}'.format(bucket, prefix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some sample data in 2D spacec using make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50000\n",
    "centers = [(-5, -5), (0, 0), (2, 2)]\n",
    "\n",
    "X, y = make_blobs(n_samples = n_samples, centers = centers, shuffle = False, random_state = 42)\n",
    "\n",
    "X = np.array(X.astype('float32'))\n",
    "y = np.array(y.astype('float32'))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify kNN, specify training data bucket as well as test data bucket, verify successfull upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'kNN'\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train, y_train)\n",
    "buf.seek(0)\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket,prefix,key)\n",
    "print('uploading training data to location: {}'.format(s3_train_data))\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpty_to_dense_tensor(buf, X_test, y_test)\n",
    "buf.seek(0)\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test', key)).upload_fileobj(buf)\n",
    "s3_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "print('uploaded test data location: {}'.format(s3_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify hyperparameters for the kNN model, and output path for the model itself. Finally, fit kNN to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'feature_dim': 2,\n",
    "    'k':3,\n",
    "    'sample_size':500,\n",
    "    'predictor_type':'classifier'\n",
    "}\n",
    "\n",
    "output_path = 's3://' + bucket + '/' + prefix + '/default_example/output'\n",
    "\n",
    "image_for_knn = get_image_uri(boto3.Session().region_name, \"knn\")\n",
    "\n",
    "knn = sagemaker.estimator.Estimator(image_for_knn,\n",
    "                                   execution_role,\n",
    "                                   train_instance_count = 1,\n",
    "                                   train_instance_type = 'ml.m5.2xlarge', # $.583/hour\n",
    "                                   output_path = output_path,\n",
    "                                   sagemaker_session = sagemaker.Session())\n",
    "\n",
    "knn.set_hyperparameters(**hyperparams)\n",
    "\n",
    "fit_input = {'train':s3_train_data}\n",
    "if s3_test_data is not None:\n",
    "    fit_input['test'] = s3_test_data\n",
    "    \n",
    "knn.fit(fit_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare instancec type, construct name and endpoint. Deploy kNN predictor with the specified information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.m4.xlarge'\n",
    "model_name = 'knn_%s' % instance_type\n",
    "endpoint_name = 'knn-ml-m4-xlarge-%s'% (str(time.time()).replace('.','-'))\n",
    "print('setting up endpoint...')\n",
    "\n",
    "knn_predictor = knn.deploy(initial_instance_count = 1, instance_type = instance_type, endpoint_name = endpoint_name)\n",
    "\n",
    "knn_predictor.content_type = 'text/csv'\n",
    "knn_predictor.serializer = csv_serializer\n",
    "knn_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models are optimized to run on batches, so split testing data into batches of size 100 each. Print accuracy upon conclusion of fitting and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = np.array_split(X_test, 100)\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = []\n",
    "for batch in batches:\n",
    "    result = knn_predictor.predict(batch)\n",
    "    cur_predictions = np.array([result['predictions'][i]['predicted_label'] for i in range(len(result['predictions']))])\n",
    "    predictions.append(cur_predictions)\n",
    "predictions = np.concatenate(predictions)\n",
    "run_time = time.time() - start_time\n",
    "\n",
    "test_size = y_test.shape[0]\n",
    "num_correct = sum(predictions == y_test)\n",
    "accuracy = num_correct / float(test_size)\n",
    "print('time required for predicting %d data point: %.2f seconds' % (test_size, run_time))\n",
    "print('accuracy of model: %.1f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the classification boundaries of the kNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test)\n",
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "df = pd.concat([X_test, predictions], axis = 1)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "df.columns = ['Feature_1', 'Feature_2', 'Class']\n",
    "\n",
    "plt.scatter(df.iloc[:,0], df.iloc[:, 1], alpha = .2, c = df.Class, cmap = 'cividis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the actual class membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test)\n",
    "y _test = pd.DataFrame(y_test)\n",
    "\n",
    "df = pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "df.columns = ['Feature_1', 'Feature_2', 'Class']\n",
    "\n",
    "plt.scatter(df.iloc[:,0], df.iloc[:, 1], alpha = 0.2, c = df.Class, cmap = 'cividis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclude by deleting the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName = predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))\n",
    "\n",
    "delete_endpoint(predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
